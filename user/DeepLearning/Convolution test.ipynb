{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([-0.1533, -0.0342,  0.1042, -0.1627], requires_grad=True)\n",
      "torch.Size([1, 4, 3, 3])\n",
      "tensor([[[ 4.1657,  4.2849,  4.4233,  4.1563],\n",
      "         [ 3.5251,  3.6443,  3.7827,  3.5157],\n",
      "         [ 0.3740,  0.4931,  0.6316,  0.3646]],\n",
      "\n",
      "        [[ 3.0414,  3.1606,  3.2990,  3.0320],\n",
      "         [ 3.0528,  3.1719,  3.3103,  3.0434],\n",
      "         [-0.0971,  0.0220,  0.1604, -0.1065]],\n",
      "\n",
      "        [[ 5.0346,  5.1538,  5.2922,  5.0252],\n",
      "         [ 5.8860,  6.0051,  6.1435,  5.8766],\n",
      "         [ 2.6092,  2.7283,  2.8667,  2.5998]]], grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outt = np.random.rand(3,3,4).astype(\"uint8\")\n",
    "#print(outt.shape)\n",
    "w = torch.ones(4,4,3,3)\n",
    "inp = torch.randn(1,4, 3, 3 )\n",
    "conv1 = nn.Conv2d(4, 4, 3, 1,1)\n",
    "conv1.weight = torch.nn.parameter.Parameter(w)\n",
    "print (conv1.weight.shape)\n",
    "print(conv1.bias)\n",
    "#inp.transpose()\n",
    "out = conv1(inp)\n",
    "print (out.shape)\n",
    "out = out.squeeze().transpose(0,2)\n",
    "\n",
    "outt[0:3,0:3] = out.detach()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(1, 1, 3, 1,1)\n",
    "print (conv1.weight.shape)\n",
    "print (conv1.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 1., 2.],\n",
      "          [3., 4., 5.],\n",
      "          [6., 7., 8.]]]])\n",
      "tensor([[[[ 8., 15., 12.],\n",
      "          [21., 36., 27.],\n",
      "          [20., 33., 24.]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "inp = torch.arange(9).reshape(1,1, 3, 3 ).float()\n",
    "w = torch.ones(1,1,3,3)\n",
    "b = torch.zeros(1)\n",
    "conv1 = nn.Conv2d(1, 1, 3, 1,1)\n",
    "conv1.weight = torch.nn.parameter.Parameter(w)\n",
    "conv1.bias = torch.nn.parameter.Parameter(b)\n",
    "out = conv1(inp)\n",
    "print(inp)\n",
    "print (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 8., 15., 12.],\n",
      "          [15., 15., 15.],\n",
      "          [15., 15., 15.]]]], grad_fn=<IndexPutBackward>)\n"
     ]
    }
   ],
   "source": [
    "out[out >15] = 15\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
      "          [ 7.,  8.,  9., 10., 11., 12., 13.],\n",
      "          [14., 15., 16., 17., 18., 19., 20.],\n",
      "          [21., 22., 23., 24., 25., 26., 27.],\n",
      "          [28., 29., 30., 31., 32., 33., 34.],\n",
      "          [35., 36., 37., 38., 39., 40., 41.],\n",
      "          [42., 43., 44., 45., 46., 47., 48.]]]])\n",
      "tensor([[[[ 8., 10., 12.],\n",
      "          [22., 24., 26.],\n",
      "          [36., 38., 40.]]]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.arange(49).reshape(1,1, 7, 7 ).float()\n",
    "maxpool = nn.MaxPool2d(2, stride=2)\n",
    "out = maxpool(inp)\n",
    "print(inp)\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,1,3)\n",
    "        self.conv2 = nn.Conv2d(1,1,3)\n",
    "        self.maxpool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        self.hidden_layer = nn.Linear(144,121)\n",
    "        self.dconv1 = nn.ConvTranspose2d(1, 1, 3, stride=1)\n",
    "        self.dconv2 = nn.ConvTranspose2d(1, 1, 4, stride=2)\n",
    "        self.dconv3 = nn.ConvTranspose2d(1, 1, 3, stride=1)\n",
    "        self.unmaxpool1 = nn.MaxUnpool2d(2,stride=2)\n",
    "        self.unmaxpool2 = nn.MaxUnpool2d(2,stride=2)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        code = self.conv1(features)\n",
    "        print(code.shape)\n",
    "        code = self.conv2(code)\n",
    "        print(code.shape)\n",
    "        code,indices = self.maxpool2(code)\n",
    "        code = code.view(-1,144)\n",
    "        print(\"hidden in shape = \" + str(code.shape))\n",
    "        code = self.hidden_layer(code)\n",
    "        code = code.view(16,1,11,11)\n",
    "        #code = self.unmaxpool1(code,indices,torch.Size([16, 1, 11, 11]))\n",
    "        #print(\"unpool out shape = \" + str(code.shape))\n",
    "        code = self.dconv1(code)\n",
    "        print(code.shape)\n",
    "        code = self.dconv2(code)\n",
    "        print(code.shape)\n",
    "        return code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 26, 26])\n",
      "torch.Size([16, 1, 24, 24])\n",
      "hidden in shape = torch.Size([16, 144])\n",
      "torch.Size([16, 1, 13, 13])\n",
      "torch.Size([16, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.arange(16 * 28 * 28).reshape(16,1, 28, 28 ).float()\n",
    "model = AE()\n",
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
