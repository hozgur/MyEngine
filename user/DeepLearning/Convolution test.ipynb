{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([-0.0671, -0.0388, -0.0719,  0.0684], requires_grad=True)\n",
      "torch.Size([1, 4, 3, 3])\n",
      "tensor([[[-5.1627, -5.1344, -5.1674, -5.0272],\n",
      "         [-1.6696, -1.6413, -1.6743, -1.5341],\n",
      "         [ 2.8976,  2.9259,  2.8928,  3.0331]],\n",
      "\n",
      "        [[-7.9837, -7.9554, -7.9884, -7.8482],\n",
      "         [-7.0002, -6.9718, -7.0049, -6.8646],\n",
      "         [-4.0452, -4.0169, -4.0499, -3.9097]],\n",
      "\n",
      "        [[-4.6906, -4.6623, -4.6954, -4.5551],\n",
      "         [-5.1071, -5.0788, -5.1118, -4.9716],\n",
      "         [-5.2826, -5.2543, -5.2874, -5.1471]]], grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outt = np.random.rand(3,3,4).astype(\"uint8\")\n",
    "#print(outt.shape)\n",
    "w = torch.ones(4,4,3,3)\n",
    "inp = torch.randn(1,4, 3, 3 )\n",
    "conv1 = nn.Conv2d(4, 4, 3, 1,1)\n",
    "conv1.weight = torch.nn.parameter.Parameter(w)\n",
    "print (conv1.weight.shape)\n",
    "print(conv1.bias)\n",
    "#inp.transpose()\n",
    "out = conv1(inp)\n",
    "print (out.shape)\n",
    "out = out.squeeze().transpose(0,2)\n",
    "\n",
    "outt[0:3,0:3] = out.detach()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(1, 1, 3, 1,1)\n",
    "print (conv1.weight.shape)\n",
    "print (conv1.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 1., 2.],\n",
      "          [3., 4., 5.],\n",
      "          [6., 7., 8.]]]])\n",
      "tensor([[[[ 8., 15., 12.],\n",
      "          [21., 36., 27.],\n",
      "          [20., 33., 24.]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "inp = torch.arange(9).reshape(1,1, 3, 3 ).float()\n",
    "w = torch.ones(1,1,3,3)\n",
    "b = torch.zeros(1)\n",
    "conv1 = nn.Conv2d(1, 1, 3, 1,1)\n",
    "conv1.weight = torch.nn.parameter.Parameter(w)\n",
    "conv1.bias = torch.nn.parameter.Parameter(b)\n",
    "out = conv1(inp)\n",
    "print(inp)\n",
    "print (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 8., 15., 12.],\n",
      "          [15., 15., 15.],\n",
      "          [15., 15., 15.]]]], grad_fn=<IndexPutBackward>)\n"
     ]
    }
   ],
   "source": [
    "out[out >15] = 15\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.],\n",
      "          [ 7.,  8.,  9., 10., 11., 12., 13.],\n",
      "          [14., 15., 16., 17., 18., 19., 20.],\n",
      "          [21., 22., 23., 24., 25., 26., 27.],\n",
      "          [28., 29., 30., 31., 32., 33., 34.],\n",
      "          [35., 36., 37., 38., 39., 40., 41.],\n",
      "          [42., 43., 44., 45., 46., 47., 48.]]]])\n",
      "tensor([[[[ 8., 10., 12.],\n",
      "          [22., 24., 26.],\n",
      "          [36., 38., 40.]]]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.arange(49).reshape(1,1, 7, 7 ).float()\n",
    "maxpool = nn.MaxPool2d(2, stride=2)\n",
    "out = maxpool(inp)\n",
    "print(inp)\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,1,3)\n",
    "        self.conv2 = nn.Conv2d(1,1,3)\n",
    "        self.maxpool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        self.hidden_layer = nn.Linear(144,25)\n",
    "        self.dconv1 = nn.ConvTranspose2d(1, 1, 3, stride=1)\n",
    "        self.dconv2 = nn.ConvTranspose2d(1, 1, 4, stride=2)\n",
    "        self.dconv3 = nn.ConvTranspose2d(1, 1, 3, stride=1)\n",
    "        self.unmaxpool1 = nn.MaxUnpool2d(2,stride=2)\n",
    "        self.unmaxpool2 = nn.MaxUnpool2d(2,stride=2)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        code = self.conv1(features)\n",
    "        print(code.shape)\n",
    "        code = self.conv2(code)\n",
    "        print(code.shape)\n",
    "        code,indices = self.maxpool2(code)\n",
    "        code = code.view(-1,144)\n",
    "        print(\"hidden in shape = \" + str(code.shape))\n",
    "        code = self.hidden_layer(code)\n",
    "        code = code.view(16,1,5,5)\n",
    "        #code = self.unmaxpool1(code,indices,torch.Size([16, 1, 11, 11]))\n",
    "        #print(\"unpool out shape = \" + str(code.shape))\n",
    "        code = self.dconv1(code)\n",
    "        print(code.shape)\n",
    "        code = self.dconv2(code)\n",
    "        print(code.shape)\n",
    "        return code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 26, 26])\n",
      "torch.Size([16, 1, 24, 24])\n",
      "hidden in shape = torch.Size([16, 144])\n",
      "torch.Size([16, 1, 7, 7])\n",
      "torch.Size([16, 1, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.arange(16 * 28 * 28).reshape(16,1, 28, 28 ).float()\n",
    "model = AE()\n",
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
