{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input = 3 * 32 * 32 = 3072 \n",
    "out = 64 * 26 * 26 = 43264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n",
      "torch.Size([10, 3072])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flatten = nn.Flatten()\n",
    "array = np.zeros((10,3,32,32),dtype=np.float32)\n",
    "array = torch.from_numpy(array)\n",
    "print(array.shape)\n",
    "array = flatten(array)\n",
    "print(array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.],\n",
      "         [ 2.,  3.]],\n",
      "\n",
      "        [[ 4.,  5.],\n",
      "         [ 6.,  7.]],\n",
      "\n",
      "        [[ 8.,  9.],\n",
      "         [10., 11.]],\n",
      "\n",
      "        [[12., 13.],\n",
      "         [14., 15.]]])\n"
     ]
    }
   ],
   "source": [
    "array = torch.Tensor(np.arange(0, 16)).reshape(4, 2, 2)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 16])\n",
      "torch.Size([24, 4, 4])\n",
      "tensor([[[328., 329., 330., 331.],\n",
      "         [344., 345., 346., 347.],\n",
      "         [360., 361., 362., 363.],\n",
      "         [376., 377., 378., 379.]],\n",
      "\n",
      "        [[332., 333., 334., 335.],\n",
      "         [348., 349., 350., 351.],\n",
      "         [364., 365., 366., 367.],\n",
      "         [380., 381., 382., 383.]]])\n"
     ]
    }
   ],
   "source": [
    "array = torch.Tensor(np.arange(0, 3 * 24*16)).reshape(3,24,16)\n",
    "print(array.shape)\n",
    "chunkSize = 4\n",
    "xChunks = int(array.shape[2]/chunkSize)\n",
    "yChunks = int(array.shape[1]/chunkSize)\n",
    "\n",
    "stride4 = 1\n",
    "stride3 = array.shape[2]\n",
    "stride2 = chunkSize\n",
    "stride1 = chunkSize * stride3\n",
    "\n",
    "array2 = array.as_strided((yChunks,xChunks,chunkSize,chunkSize), (stride1,stride2,stride3,stride4)).flatten(0,1)\n",
    "print(array2.shape)\n",
    "print(array2[22:24,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Tensor Shape: torch.Size([1024, 2048, 3])\n",
      "Image size: 2048x1024\n",
      "xChunks: 4\n",
      "yChunks: 4\n",
      "torch.Size([16, 256, 512, 3])\n",
      "(393216, 1536, 3, 1)\n",
      "chunk shape =  torch.Size([512, 3])\n"
     ]
    }
   ],
   "source": [
    "trainImage = Image.open(\"./testrgb.png\")\n",
    "chunkSizeX = 512\n",
    "chunkSizeY = 256\n",
    "trainImageTensor = torch.tensor(np.array(trainImage))\n",
    "#trainImageTensor = torch.transpose(trainImageTensor, 2, 0).transpose(1,2)/255.0\n",
    "print(\"Image Tensor Shape: \" + str(trainImageTensor.shape))\n",
    "width = trainImageTensor.shape[1]\n",
    "height = trainImageTensor.shape[0]\n",
    "print(\"Image size: \" + str(width) + \"x\" + str(height))\n",
    "\n",
    "xChunks = int((width)/chunkSizeX)\n",
    "yChunks = int((height)/chunkSizeY)\n",
    "chunks = xChunks * yChunks\n",
    "print(\"xChunks: \" + str(xChunks))\n",
    "print(\"yChunks: \" + str(yChunks))\n",
    "stride4 = 1\n",
    "stride3 = 3\n",
    "stride2 = width*3\n",
    "stride1 = chunkSizeX\n",
    "stride0 = chunkSizeY*width*3\n",
    "trainImageChunks = trainImageTensor[0].as_strided((yChunks, xChunks,chunkSizeY, chunkSizeX,3), (stride0, stride1, stride2, stride3, stride4)).flatten(0,1)\n",
    "print(trainImageChunks.shape)\n",
    "print(trainImageChunks.stride())\n",
    "print(\"chunk shape = \",trainImageChunks[0,0].shape)\n",
    "for i in range(0, 3):\n",
    "    chunk = trainImageChunks[i].cpu()    \n",
    "    chunk = np.uint8(chunk)#.transpose(1,2,0)\n",
    "    img = Image.fromarray(chunk).save(\"./images/test-out_\"+str(i)+\".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Tensor Shape: torch.Size([1024, 2048, 4])\n",
      "Image Tensor Shape: torch.Size([4, 1024, 2048])\n",
      "Image size: 2048x1024\n",
      "xChunks: 4\n",
      "yChunks: 4\n",
      "torch.Size([4, 4, 256, 512])\n",
      "(1048576, 0, 2048, 1)\n",
      "chunk shape =  torch.Size([256, 512])\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d50220305086dde7714464d39eb812e6992001230edb4d06ec4afb2ffb1c28c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
