{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, inChannels=3, chunkSizeX = 32,chunkSizeY = 32):\n",
    "        super(CNN, self).__init__()\n",
    "        self.chunkSizeX = chunkSizeX\n",
    "        self.chunkSizeY = chunkSizeY\n",
    "        self.intermediateSize = 3 * chunkSizeX *chunkSizeY\n",
    "        self.transfer = nn.Sigmoid()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=3*chunkSizeX*chunkSizeY, out_features=self.intermediateSize),\n",
    "            nn.ReLU(),\n",
    "        )                \n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.unflatten  = nn.Unflatten(1, (3,chunkSizeY,chunkSizeX))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=self.intermediateSize, out_features=3*chunkSizeX*chunkSizeY),\n",
    "            self.transfer,\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.flatten(x)\n",
    "        out = self.encoder(out)\n",
    "        out = self.decoder(out)\n",
    "        out = self.unflatten(out)\n",
    "        return out\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Tensor Shape: torch.Size([2048, 4096, 3])\n",
      "Image size: 4096x2048\n",
      "Remains: 0 - 0\n",
      "trainImageTensor shape after crop=  torch.Size([2048, 4096, 3])\n",
      "New Image size: 4096x2048\n",
      "xChunks: 128\n",
      "yChunks: 64\n",
      "Chunks: 8192\n",
      "torch.Size([8192, 32, 32, 3])\n",
      "chunk shape =  torch.Size([32, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create Data Set\n",
    "trainImage = Image.open(\"./test-cropped.png\")\n",
    "chunkSizeX = model.chunkSizeX\n",
    "chunkSizeY = model.chunkSizeY\n",
    "trainImageTensor = torch.tensor(np.array(trainImage)).to(device)/255.\n",
    "print(\"Image Tensor Shape: \" + str(trainImageTensor.shape))\n",
    "width = trainImageTensor.shape[1]\n",
    "height = trainImageTensor.shape[0]\n",
    "print(\"Image size: \" + str(width) + \"x\" + str(height))\n",
    "xRemain = width % chunkSizeX\n",
    "yRemain = height % chunkSizeY\n",
    "print(\"Remains: \" + str(xRemain) + \" - \" + str(yRemain))\n",
    "trainImageTensor = trainImageTensor[0:height-yRemain, 0:width-xRemain,:]\n",
    "width = trainImageTensor.shape[1]\n",
    "height = trainImageTensor.shape[0]\n",
    "print(\"trainImageTensor shape after crop= \",trainImageTensor.shape)\n",
    "print(\"New Image size: \" + str(width) + \"x\" + str(height))\n",
    "\n",
    "xChunks = int((width)/chunkSizeX)\n",
    "yChunks = int((height)/chunkSizeY)\n",
    "chunks = xChunks * yChunks\n",
    "print(\"xChunks: \" + str(xChunks))\n",
    "print(\"yChunks: \" + str(yChunks))\n",
    "print(\"Chunks: \" + str(chunks))\n",
    "stride4 = 1\n",
    "stride3 = 3\n",
    "stride2 = width*3\n",
    "stride1 = chunkSizeX\n",
    "stride0 = chunkSizeY*width*3\n",
    "trainImageChunks = trainImageTensor.as_strided((yChunks, xChunks,chunkSizeY, chunkSizeX,3), (stride0,stride1, stride2, stride3, stride4)).flatten(0,1)\n",
    "print(trainImageChunks.shape)\n",
    "print(\"chunk shape = \",trainImageChunks[0].shape)\n",
    "\n",
    "for i in range(0, 32):\n",
    "    chunk = trainImageChunks[8192-32+i].cpu()\n",
    "    img = Image.fromarray(np.uint8(chunk*255)).save(\"./images/test-out_\"+str(i)+\".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchCount =  256\n",
      "Epoch: 1 Loss: 0.00040637419442646205\n",
      "Epoch: 2 Loss: 0.0004094888863619417\n",
      "Epoch: 3 Loss: 0.0004147384315729141\n",
      "Epoch: 4 Loss: 0.0004154706548433751\n",
      "Epoch: 5 Loss: 0.00041548986337147653\n",
      "Epoch: 6 Loss: 0.0004138938966207206\n",
      "Epoch: 7 Loss: 0.0004111786838620901\n",
      "Epoch: 8 Loss: 0.0004088580026291311\n",
      "Epoch: 9 Loss: 0.00040633039316162467\n",
      "Epoch: 10 Loss: 0.0004040311323478818\n",
      "Epoch: 11 Loss: 0.0004016394668724388\n",
      "Epoch: 12 Loss: 0.00040006660856306553\n",
      "Epoch: 13 Loss: 0.0003991770790889859\n",
      "Epoch: 14 Loss: 0.00039898190880194306\n",
      "Epoch: 15 Loss: 0.00039893988287076354\n",
      "Epoch: 16 Loss: 0.0003987892996519804\n",
      "Epoch: 17 Loss: 0.00039862707490101457\n",
      "Epoch: 18 Loss: 0.0003984566719736904\n",
      "Epoch: 19 Loss: 0.0003980707551818341\n",
      "Epoch: 20 Loss: 0.0003974259307142347\n",
      "Epoch: 21 Loss: 0.00039743143133819103\n",
      "Epoch: 22 Loss: 0.0003979154280386865\n",
      "Epoch: 23 Loss: 0.00039836502401158214\n",
      "Epoch: 24 Loss: 0.0003987055388279259\n",
      "Epoch: 25 Loss: 0.0003990711993537843\n",
      "Epoch: 26 Loss: 0.00039967638440430164\n",
      "Epoch: 27 Loss: 0.00040016433922573924\n",
      "Epoch: 28 Loss: 0.0003982789348810911\n",
      "Epoch: 29 Loss: 0.0003962570335716009\n",
      "Epoch: 30 Loss: 0.00039493758231401443\n",
      "Epoch: 31 Loss: 0.0003942372277379036\n",
      "Epoch: 32 Loss: 0.0003942721523344517\n",
      "Epoch: 33 Loss: 0.00039470853516831994\n",
      "Epoch: 34 Loss: 0.00039524780004285276\n",
      "Epoch: 35 Loss: 0.00039574201218783855\n",
      "Epoch: 36 Loss: 0.0003953212290070951\n",
      "Epoch: 37 Loss: 0.00039447820745408535\n",
      "Epoch: 38 Loss: 0.0003950633981730789\n",
      "Epoch: 39 Loss: 0.000397148949559778\n",
      "Epoch: 40 Loss: 0.00039944512536749244\n",
      "Epoch: 41 Loss: 0.00040401433943770826\n",
      "Epoch: 42 Loss: 0.0004068099078722298\n",
      "Epoch: 43 Loss: 0.0004060434293933213\n",
      "Epoch: 44 Loss: 0.0004066856927238405\n",
      "Epoch: 45 Loss: 0.00040457199793308973\n",
      "Epoch: 46 Loss: 0.00040166493272408843\n",
      "Epoch: 47 Loss: 0.00039843603735789657\n",
      "Epoch: 48 Loss: 0.0003958126762881875\n",
      "Epoch: 49 Loss: 0.0003933035768568516\n",
      "Epoch: 50 Loss: 0.0003916159621439874\n",
      "Epoch: 51 Loss: 0.000390677887480706\n",
      "Epoch: 52 Loss: 0.0003904977347701788\n",
      "Epoch: 53 Loss: 0.0003906050114892423\n",
      "Epoch: 54 Loss: 0.0003905633930116892\n",
      "Epoch: 55 Loss: 0.00039040143019519746\n",
      "Epoch: 56 Loss: 0.00039015780203044415\n",
      "Epoch: 57 Loss: 0.0003896942362189293\n",
      "Epoch: 58 Loss: 0.0003891954547725618\n",
      "Epoch: 59 Loss: 0.0003890130901709199\n",
      "Epoch: 60 Loss: 0.0003893873072229326\n",
      "Epoch: 61 Loss: 0.0003900544252246618\n",
      "Epoch: 62 Loss: 0.0003904695331584662\n",
      "Epoch: 63 Loss: 0.00039179716259241104\n",
      "Epoch: 64 Loss: 0.0003925281926058233\n",
      "Epoch: 65 Loss: 0.00039174931589514017\n",
      "Epoch: 66 Loss: 0.00039088260382413864\n",
      "Epoch: 67 Loss: 0.00038858765037730336\n",
      "Epoch: 68 Loss: 0.0003870233194902539\n",
      "Epoch: 69 Loss: 0.00038608373142778873\n",
      "Epoch: 70 Loss: 0.00038596673402935266\n",
      "Epoch: 71 Loss: 0.0003860592842102051\n",
      "Epoch: 72 Loss: 0.00038691851659677923\n",
      "Epoch: 73 Loss: 0.0003870721848215908\n",
      "Epoch: 74 Loss: 0.00038653131923638284\n",
      "Epoch: 75 Loss: 0.0003860558499582112\n",
      "Epoch: 76 Loss: 0.00038606557063758373\n",
      "Epoch: 77 Loss: 0.0003876146802213043\n",
      "Epoch: 78 Loss: 0.00038960500387474895\n",
      "Epoch: 79 Loss: 0.0003926630306523293\n",
      "Epoch: 80 Loss: 0.00039723276859149337\n",
      "Epoch: 81 Loss: 0.00039924937300384045\n",
      "Epoch: 82 Loss: 0.0003998232714366168\n",
      "Epoch: 83 Loss: 0.0003980598412454128\n",
      "Epoch: 84 Loss: 0.00039507573819719255\n",
      "Epoch: 85 Loss: 0.00039224614738486707\n",
      "Epoch: 86 Loss: 0.0003895952831953764\n",
      "Epoch: 87 Loss: 0.0003868471540044993\n",
      "Epoch: 88 Loss: 0.0003845969622489065\n",
      "Epoch: 89 Loss: 0.00038302497705444694\n",
      "Epoch: 90 Loss: 0.00038237893022596836\n",
      "Epoch: 91 Loss: 0.00038240323192439973\n",
      "Epoch: 92 Loss: 0.0003825083840638399\n",
      "Epoch: 93 Loss: 0.0003823402221314609\n",
      "Epoch: 94 Loss: 0.0003823054430540651\n",
      "Epoch: 95 Loss: 0.00038201603456400335\n",
      "Epoch: 96 Loss: 0.00038163107819855213\n",
      "Epoch: 97 Loss: 0.0003811411443166435\n",
      "Epoch: 98 Loss: 0.0003812299983110279\n",
      "Epoch: 99 Loss: 0.0003818375989794731\n",
      "Epoch: 100 Loss: 0.0003816628595814109\n"
     ]
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"./model1.pth\"))\n",
    "#model.eval()\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "optimizer = optim.SGD(model.parameters(), lr=10, momentum=0.1)\n",
    "writer = SummaryWriter()\n",
    "# create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "# train the model\n",
    "batchSize = 32\n",
    "epochs = 100\n",
    "batchCount = int(chunks/batchSize)\n",
    "print (\"batchCount = \",batchCount)\n",
    "for epoch in range(1, epochs+1):\n",
    "    for batch in range(0, batchCount):\n",
    "        batchStart = batch * batchSize\n",
    "        batchEnd = batchStart + batchSize\n",
    "        if(batchEnd > chunks):\n",
    "            batchEnd = chunks\n",
    "        batchTensor = trainImageChunks[batchStart:batchEnd].transpose(1,3).transpose(2,3)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batchTensor)\n",
    "        loss = criterion(output, batchTensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(\"Batch: \" + str(batch) + \" Loss: \" + str(loss.item()))    \n",
    "    print(\"Epoch: \" + str(epoch) + \" Loss: \" + str(loss.item()))    \n",
    "    inputExamples = batchTensor[0:10,:,:,:]\n",
    "    outputExamples = output[0:10,:,:,:]\n",
    "    inputGrid = torchvision.utils.make_grid(inputExamples)\n",
    "    outputGrid = torchvision.utils.make_grid(outputExamples)\n",
    "    writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "    writer.add_image('input', inputGrid, epoch)\n",
    "    writer.add_image('output', outputGrid, epoch)\n",
    "    writer.flush()\n",
    "\n",
    "# save the model\n",
    "torch.save(model.state_dict(), \"./model2.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d50220305086dde7714464d39eb812e6992001230edb4d06ec4afb2ffb1c28c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
